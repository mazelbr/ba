{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matze\\Documents\\Winton\\CRISPDM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "print(os.getcwd()) \n",
    "\n",
    "X = pd.read_csv('X_features.csv', index_col=0)\n",
    "y = pd.read_csv('y_features.csv', index_col=0)\n",
    "groups = X.pop('Feature_7')\n",
    "\n",
    "test = pd.read_csv('test_features.csv', index_col=0).drop(columns = 'Feature_7')\n",
    "sample = pd.read_csv('sample_submission_2.csv')\n",
    "df_train = pd.read_csv('train.csv').set_index('Id')\n",
    "df_test = pd.read_csv('test_2.csv').set_index('Id')\n",
    "weights = df_train.loc[:,'Weight_Intraday':'Weight_Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper\n",
    "def typecasting(df):\n",
    "    categorial_cols = ['Feature_20','Feature_5']\n",
    "    binary_cols = ['Feature_16']\n",
    "\n",
    "    for col in categorial_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    for col in binary_cols:\n",
    "        df[col] = (df[col]-1).astype('category')\n",
    "\n",
    "def trainscore(y_true,y_pred,weights):\n",
    "    weights = weights.loc[y_true.index,:]\n",
    "    daily = pd.concat([weights.Weight_Daily]*2,axis=1)\n",
    "    minute = pd.concat([weights.Weight_Intraday]*60,axis=1)\n",
    "    weights = pd.concat([minute,daily],axis=1)\n",
    "    weights.columns = df_train.loc[:,'Ret_121':'Ret_PlusTwo'].columns\n",
    "    \n",
    "    \n",
    "    wmea = (((abs(y_true-y_pred))*weights).values.flatten().sum()/y_true.size)\n",
    "    \n",
    "    \n",
    "    #minute_ret = abs(y_true.loc[:,'Ret_121':'180']-y_pred.loc[:,'Ret_121':'Ret_180'])*weights.Weight_Intraday\n",
    "    return wmea\n",
    "\n",
    "\n",
    "def create_core_features(train,test):\n",
    "    X_train=train.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    X_val=test.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    from sklearn.preprocessing import Imputer\n",
    "\n",
    "    typecasting(X_train)\n",
    "    X_train = pd.get_dummies(X_train,drop_first=True)\n",
    "\n",
    "    typecasting(X_val)\n",
    "    X_val = pd.get_dummies(X_val,drop_first=True)\n",
    "\n",
    "    imputer = Imputer(strategy='mean', axis=0)\n",
    "    X_train = pd.DataFrame(imputer.fit_transform(X_train), index= X_train.index,columns=X_train.columns)\n",
    "    X_val = pd.DataFrame(imputer.fit_transform(X_val), index= X_val.index,columns=X_val.columns)\n",
    "    X_train['Ret_MinutePast'] = train.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    X_val['Ret_MinutePast'] = test.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_features, core_features_test = create_core_features(df_train,df_test)\n",
    "# generated features is X\n",
    "#Adding the interactions to Featureset\n",
    "crafted_features = pd.read_csv('BA_Features/X_features_BA.csv', index_col=0)\n",
    "crafted_features_test = pd.read_csv('BA_Features/test_features_BA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 102) (120000, 102)\n"
     ]
    }
   ],
   "source": [
    "crafted_features['interaction_3']= crafted_features.PR_120 * crafted_features.grouped_mad_fet_7\n",
    "crafted_features_test['interaction_3']= crafted_features_test.PR_120 * test.grouped_mad_fet_7\n",
    "\n",
    "#X['interaction_4']= X.smoothed_minute_mean * X.minute_mad\n",
    "#test['interaction_4']= test.smoothed_minute_mean * test.minute_mad\n",
    "\n",
    "crafted_features['interaction_5']= crafted_features.minute_mad * crafted_features.PR_120\n",
    "crafted_features_test['interaction_5']= crafted_features_test.minute_mad * crafted_features_test.PR_120\n",
    "\n",
    "crafted_features['interaction_6']= crafted_features.smoothed_minute_mean * crafted_features.grouped_mad_fet_5\n",
    "crafted_features_test['interaction_6']= crafted_features_test.smoothed_minute_mean * crafted_features_test.grouped_mad_fet_5\n",
    "\n",
    "crafted_features['interaction_7']= crafted_features.PR_120 * crafted_features.fet_7_Minute_MAD\n",
    "crafted_features_test['interaction_7']= crafted_features_test.PR_120 * crafted_features_test.fet_7_Minute_MAD\n",
    "\n",
    "crafted_features['interaction_8']= crafted_features.fet_7_Minute_MAD * crafted_features.fet_7_Minute_Mean\n",
    "crafted_features_test['interaction_8']= crafted_features_test.fet_7_Minute_MAD * crafted_features_test.fet_7_Minute_Mean\n",
    "\n",
    "print(crafted_features.shape,crafted_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([core_features,crafted_features],axis=1).drop('Feature_7',axis='columns')\n",
    "all_features_test = pd.concat([core_features_test,crafted_features_test],axis=1).drop('Feature_7',axis='columns')\n",
    "\n",
    "features_and_target = all_features.copy()\n",
    "features_and_target['Ret_PlusOne'] = y.Ret_PlusOne\n",
    "features_and_target['Ret_PlusTwo'] = y.Ret_PlusTwo\n",
    "features_and_target = features_and_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109.554 s\n",
      "time: 112.161 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "corr_spearman = features_and_target.corr(method='spearman').to_csv('BA_Features/spearman_cor.csv')\n",
    "print(\"time:\", round(time.time()-t0, 3), \"s\")\n",
    "corr_pearson = features_and_target.corr(method='pearson').to_csv('BA_Features/pearson_cor.csv')\n",
    "print(\"time:\", round(time.time()-t0, 3), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spearman = pd.read_csv('BA_Features/spearman_cor.csv',index_col=0)\n",
    "corr_pearson = pd.read_csv('BA_Features/pearson_cor.csv',index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(corr_pearson.Ret_PlusOne).sort_values(ascending=False)[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "n=20000\n",
    "\n",
    "t0 = time.time()\n",
    "mic_Ret_PlusOne = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0), random_state=0)\n",
    "print('Time: ',time.time()-t0)\n",
    "t0 = time.time()\n",
    "#select10 = SelectKBest(score_func=mutual_info_regression, k=20).fit(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0))\n",
    "print('Time: ',time.time()-t0)\n",
    "mic_Ret_PlusTwo = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusTwo.sample(n,random_state=0), random_state=0)\n",
    "print('Time: ',time.time()-t0)\n",
    "t0 = time.time()\n",
    "mic_Ret_Minute = mutual_info_regression(all_features.sample(n,random_state=0), df_train.loc[:,'Ret_121':'Ret_180'].sum(axis=1).sample(n,random_state=0), random_state=0)\n",
    "\n",
    "print('Time: ',time.time()-t0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([mic_Ret_PlusOne,mic_Ret_PlusTwo,mic_Ret_Minute], index = ['MIC_PlusOne','MIC_PlusTwo','MIC_Minute'],columns=all_features.columns.values).T.to_csv('BA_Features/MIC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIC = pd.read_csv('BA_Features/MIC.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Ret_PlusOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(gs.best_estimator_,n_features_to_select=n, step=1, verbose=1)\n",
    "rfe.fit(train, y.Ret_PlusOne)\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "\n",
    "cols_to_use = train.columns[rfe.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic10 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:10].index\n",
    "mic20 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:20].index\n",
    "mic30 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:30].index\n",
    "corr10 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[1:11].index\n",
    "corr20 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[1:21].index\n",
    "corr30 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[1:31].index\n",
    "corrPear = abs(corr_pearson.Ret_PlusOne).sort_values(ascending=False)[1:21].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = pd.DataFrame([mic10,mic20,mic30,corr10,corr20,corr30],index=['mic10','mic20','mic30','corr10','corr20','corr30'],columns=list(range(1,31))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BA_Submissions/Ridge_mic10.csv'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ridge', 'Ridge', 'Ridge']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx = pd.DataFrame([name,algo,mae]).T\n",
    "xxx.append(pd.DataFrame([algo,algo,algo]).T)\n",
    "[algo,algo,algo]\n",
    "startrow = writer.book[sheet_name].max_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "\n",
    "results = pd.DataFrame(columns=['algo','featureset','fitting_time','zerobenchmark','validationmark','mae','params'])\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "#name='mic10'\n",
    "    target= 'Ret_PlusOne'\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    learner = Ridge()\n",
    "    param_grid= {'alpha': [20,19,18,17,16,15,12,11,10,8,6,4,2,1,0.5],'normalize':[True],'max_iter':[700]}\n",
    "\n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(all_features[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    #sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+\".csv\"), index=False)\n",
    "\n",
    "    ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('BA_Submissions/Results.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-c8a988c20ecf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRet_PlusOne\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training time:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "#rfe\n",
    "n = 20\n",
    "\n",
    "t0=time.time()\n",
    "rfe = RFE(gs.best_estimator_,n_features_to_select=n, step=1, verbose=1)\n",
    "rfe.fit(train, y.Ret_PlusOne)\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "\n",
    "cols_to_use = train.columns[rfe.get_support(indices=True)]\n",
    "gs= GridSearchCV(gbm, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(all_features[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "\n",
    "\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "sample.to_csv('submissions/GBM_featureset_RFE_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Huber\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "#(estimator, n_features_to_select=None, step=1, verbose=0)\n",
    "\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = Huber()\n",
    "param_grid= {'alpha': [100,20,19,18,17,16,15,12,11,1,0.1],'epsilon':[1,1.35,1.8],'max_iter':[700]}\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = RandomForestRegressor()\n",
    "param_grid= {'bootstrap': [True, False],#kein plan also auch weg\n",
    "             'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],#tiefer\n",
    "             'max_features': ['auto', 'sqrt'],#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [1, 2, 4], #höher\n",
    "             'min_samples_split': [2, 5, 10],#kann wahrscheinlich weg\n",
    "             'n_estimators': [200, 400, 600]}#mehr bedeuten dauert länger\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.ensemble import GradientBoostRegressor\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = GradientBoostRegressor()\n",
    "param_grid= {'bootstrap': [True, False],#kein plan also auch weg\n",
    "             'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],#tiefer\n",
    "             'max_features': ['auto', 'sqrt'],#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [1, 2, 4], #höher\n",
    "             'min_samples_split': [2, 5, 10],#kann wahrscheinlich weg\n",
    "             'n_estimators': [200, 400, 600]}#mehr bedeuten dauert länger\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
