{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matze\\Documents\\Winton\\CRISPDM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "print(os.getcwd()) \n",
    "\n",
    "X = pd.read_csv('X_features.csv', index_col=0)\n",
    "y = pd.read_csv('y_features.csv', index_col=0)\n",
    "groups = X.pop('Feature_7')\n",
    "\n",
    "test = pd.read_csv('test_features.csv', index_col=0).drop(columns = 'Feature_7')\n",
    "sample = pd.read_csv('sample_submission_2.csv')\n",
    "df_train = pd.read_csv('train.csv').set_index('Id')\n",
    "df_test = pd.read_csv('test_2.csv').set_index('Id')\n",
    "weights = df_train.loc[:,'Weight_Intraday':'Weight_Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper\n",
    "def typecasting(df):\n",
    "    categorial_cols = ['Feature_20','Feature_5']\n",
    "    binary_cols = ['Feature_16']\n",
    "\n",
    "    for col in categorial_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    for col in binary_cols:\n",
    "        df[col] = (df[col]-1).astype('category')\n",
    "\n",
    "def trainscore(y_true,y_pred,weights):\n",
    "    weights = weights.loc[y_true.index,:]\n",
    "    daily = pd.concat([weights.Weight_Daily]*2,axis=1)\n",
    "    minute = pd.concat([weights.Weight_Intraday]*60,axis=1)\n",
    "    weights = pd.concat([minute,daily],axis=1)\n",
    "    weights.columns = df_train.loc[:,'Ret_121':'Ret_PlusTwo'].columns\n",
    "    \n",
    "    \n",
    "    wmea = (((abs(y_true-y_pred))*weights).values.flatten().sum()/y_true.size)\n",
    "    \n",
    "    \n",
    "    #minute_ret = abs(y_true.loc[:,'Ret_121':'180']-y_pred.loc[:,'Ret_121':'Ret_180'])*weights.Weight_Intraday\n",
    "    return wmea\n",
    "\n",
    "\n",
    "def create_core_features(train,test):\n",
    "    X_train=train.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    X_val=test.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    from sklearn.preprocessing import Imputer\n",
    "\n",
    "    typecasting(X_train)\n",
    "    X_train = pd.get_dummies(X_train,drop_first=True)\n",
    "\n",
    "    typecasting(X_val)\n",
    "    X_val = pd.get_dummies(X_val,drop_first=True)\n",
    "\n",
    "    imputer = Imputer(strategy='mean', axis=0)\n",
    "    X_train = pd.DataFrame(imputer.fit_transform(X_train), index= X_train.index,columns=X_train.columns)\n",
    "    X_val = pd.DataFrame(imputer.fit_transform(X_val), index= X_val.index,columns=X_val.columns)\n",
    "    X_train['Ret_MinutePast'] = train.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    X_val['Ret_MinutePast'] = test.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_features, core_features_test = create_core_features(df_train,df_test)\n",
    "# generated features is X\n",
    "#Adding the interactions to Featureset\n",
    "crafted_features = pd.read_csv('BA_Features/X_features_BA.csv', index_col=0)\n",
    "crafted_features_test = pd.read_csv('BA_Features/test_features_BA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 102) (120000, 102)\n"
     ]
    }
   ],
   "source": [
    "crafted_features['interaction_3']= crafted_features.PR_120 * crafted_features.grouped_mad_fet_7\n",
    "crafted_features_test['interaction_3']= crafted_features_test.PR_120 * test.grouped_mad_fet_7\n",
    "\n",
    "#X['interaction_4']= X.smoothed_minute_mean * X.minute_mad\n",
    "#test['interaction_4']= test.smoothed_minute_mean * test.minute_mad\n",
    "\n",
    "crafted_features['interaction_5']= crafted_features.minute_mad * crafted_features.PR_120\n",
    "crafted_features_test['interaction_5']= crafted_features_test.minute_mad * crafted_features_test.PR_120\n",
    "\n",
    "crafted_features['interaction_6']= crafted_features.smoothed_minute_mean * crafted_features.grouped_mad_fet_5\n",
    "crafted_features_test['interaction_6']= crafted_features_test.smoothed_minute_mean * crafted_features_test.grouped_mad_fet_5\n",
    "\n",
    "crafted_features['interaction_7']= crafted_features.PR_120 * crafted_features.fet_7_Minute_MAD\n",
    "crafted_features_test['interaction_7']= crafted_features_test.PR_120 * crafted_features_test.fet_7_Minute_MAD\n",
    "\n",
    "crafted_features['interaction_8']= crafted_features.fet_7_Minute_MAD * crafted_features.fet_7_Minute_Mean\n",
    "crafted_features_test['interaction_8']= crafted_features_test.fet_7_Minute_MAD * crafted_features_test.fet_7_Minute_Mean\n",
    "\n",
    "print(crafted_features.shape,crafted_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([core_features,crafted_features],axis=1).drop('Feature_7',axis='columns')\n",
    "all_features_test = pd.concat([core_features_test,crafted_features_test],axis=1).drop('Feature_7',axis='columns')\n",
    "\n",
    "features_and_target = all_features.copy()\n",
    "features_and_target['Ret_PlusOne'] = y.Ret_PlusOne\n",
    "features_and_target['Ret_PlusTwo'] = y.Ret_PlusTwo\n",
    "features_and_target['Ret_MinutesFut'] = df_train.loc[:,'Ret_121':'Ret_180'].sum(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 111.148 s\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "#t0=time.time()\n",
    "#corr_spearman = features_and_target.corr(method='spearman').to_csv('BA_Features/spearman_cor.csv')\n",
    "print(\"time:\", round(time.time()-t0, 3), \"s\")\n",
    "#corr_pearson = features_and_target.corr(method='pearson').to_csv('BA_Features/pearson_cor.csv')\n",
    "#print(\"time:\", round(time.time()-t0, 3), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "n=20000\n",
    "\n",
    "t0 = time.time()\n",
    "mic_Ret_PlusOne = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0), random_state=0)\n",
    "print('Time: ',time.time()-t0)\n",
    "t0 = time.time()\n",
    "#select10 = SelectKBest(score_func=mutual_info_regression, k=20).fit(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0))\n",
    "print('Time: ',time.time()-t0)\n",
    "mic_Ret_PlusTwo = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusTwo.sample(n,random_state=0), random_state=0)\n",
    "print('Time: ',time.time()-t0)\n",
    "t0 = time.time()\n",
    "mic_Ret_Minute = mutual_info_regression(all_features.sample(n,random_state=0), df_train.loc[:,'Ret_121':'Ret_180'].sum(axis=1).sample(n,random_state=0), random_state=0)\n",
    "\n",
    "print('Time: ',time.time()-t0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([mic_Ret_PlusOne,mic_Ret_PlusTwo,mic_Ret_Minute], index = ['MIC_PlusOne','MIC_PlusTwo','MIC_Minute'],columns=all_features.columns.values).T.to_csv('BA_Features/MIC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import PolynomialFeatures\n",
    "poly=PolynomialFeatures()\n",
    "X_poly = pd.read_csv('X_features_2.csv', index_col=0)\n",
    "X_poly_test = pd.read_csv('test_features_2.csv', index_col=0)\n",
    "X_poly = pd.DataFrame(poly.fit_transform(X_poly), columns= poly.get_feature_names(),index=X_poly.index).drop(['1'],axis='columns')\n",
    "X_poly_test=pd.DataFrame(poly.fit_transform(X_poly_test), columns= poly.get_feature_names(),index=X_poly_test.index).drop(['1'],axis='columns')\n",
    "display(X_poly.head())\n",
    "display(X_poly_test.head())\n",
    "\n",
    "X_poly_and_target = X_poly.copy()\n",
    "X_poly_and_target['Ret_PlusOne'] = y.Ret_PlusOne\n",
    "X_poly_and_target['Ret_PlusTwo'] = y.Ret_PlusTwo\n",
    "X_poly_and_target['Ret_MinutesFut'] = df_train.loc[:,'Ret_121':'Ret_180'].sum(axis=1)\n",
    "\n",
    "X_poly_and_target.corr(method='spearman').to_csv('BA_Features/poly_cor.csv')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIC = pd.read_csv('BA_Features/MIC.csv', index_col=0)\n",
    "corr_spearman = pd.read_csv('BA_Features/spearman_cor.csv',index_col=0).drop(['Ret_MinutesFut','Ret_PlusOne','Ret_PlusTwo'])\n",
    "corr_poly = pd.read_csv('BA_Features/poly_cor.csv',index_col=0).drop(['Ret_MinutesFut','Ret_PlusOne','Ret_PlusTwo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIC_poly = pd.read_csv('BA_Features/MIC_Poly.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Ret_PlusOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featuresets (Needed once for each Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['algo','featureset','target','fitting_time','zerobenchmark','validationmark','mae','params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic10 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:10].index\n",
    "mic20 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:20].index\n",
    "mic30 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:30].index\n",
    "corr10 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[0:10].index\n",
    "corr20 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[0:20].index\n",
    "corr30 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[0:30].index\n",
    "core=core_features.drop('Feature_7',axis='columns').columns.values\n",
    "poly15_1 = ['x1 x8','x3 x16', 'x5 x10', 'x5 x16', 'x5', 'x5 x6', 'x3 x6', 'x3 x5', 'x5 x11', 'x3 x10', 'x3^2', 'x2^2', 'x3', 'x3 x12']\n",
    "poly15_2 = abs(corr_poly.Ret_PlusOne).sort_values(ascending=False)[0:15].index\n",
    "micpoly15 = MIC_poly.MIC_PlusOne.sort_values(ascending=False)[0:15].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 507.368 s\n",
      "training time: 520.664 s\n",
      "training time: 533.558 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'rfe10', 'rfe20', 'rfe30', 'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RFE Params\n",
    "rfe_learner = Ridge()\n",
    "rfe_params ={'alpha':100,'normalize':True,'max_iter':700,'random_state':[0]}\n",
    "rfe_learner = rfe_learner.set_params(**rfe_params)\n",
    "rfe_target = 'Ret_PlusOne'\n",
    "\n",
    "#RFE Fitting\n",
    "rfe = RFE(rfe_learner,n_features_to_select=10, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe10 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=20, step=1, verbose=0)\n",
    "rfe.fit(all_features, y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe20 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=30, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe30 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = Ridge()\n",
    "target= 'Ret_PlusOne'\n",
    "param_grid= {'alpha': [20,19,18,17,16,15,12,11,10,8,6,4,2,1,0.5],'normalize':[True],'max_iter':[700],'random_state':[0]}\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,rfe10,rfe20,rfe30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','rfe10','rfe20','rfe30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "         ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model_Params\n",
    "\n",
    "learner = HuberRegressor()\n",
    "target= 'Ret_PlusOne'\n",
    "param_grid= {'alpha': [100,20,19,18,17,16,15,12,11,10],'max_iter':[700]}\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "         ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = ExtraTreesRegressor()\n",
    "target= 'Ret_PlusOne'\n",
    "param_grid= {'max_depth': [3],#tiefer\n",
    "             \n",
    "             'max_features': 'auto',#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [5000], #höher\n",
    "             #'min_samples_split': [],\n",
    "             'n_estimators': [100,150],#mehr bedeuten dauert länger\n",
    "             'n_jobs':[-1],\n",
    "            'random_state':[0],\n",
    "            'max_features':['sqrt']}\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "     ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "337.34855222702026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "164.78439211845398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "228.82843470573425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "275.67026925086975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "164.50741696357727"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "239.9802281856537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "307.3225631713867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "196.24394154548645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "173.72495865821838"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "186.17970418930054"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = GradientBoostingRegressor()\n",
    "target= 'Ret_PlusOne'\n",
    "param_grid= {'loss':['lad'],\n",
    "             'learning_rate':[0.001],\n",
    "            'max_depth': [3],\n",
    "             'n_estimators': [300,400],\n",
    "            'random_state':[0],\n",
    "            'subsample':[0.5],\n",
    "             'verbose':[0],\n",
    "            'max_features':['auto','sqrt']}\n",
    "             \n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "    display(fitting_time)\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "    ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel((\"BA_Submissions/results_\"+target+\".xls\"),header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ret_PlusTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic10 = MIC.MIC_PlusTwo.sort_values(ascending=False)[0:10].index\n",
    "mic20 = MIC.MIC_PlusTwo.sort_values(ascending=False)[0:20].index\n",
    "mic30 = MIC.MIC_PlusTwo.sort_values(ascending=False)[0:30].index\n",
    "corr10 = abs(corr_spearman.Ret_PlusTwo).sort_values(ascending=False)[0:10].index\n",
    "corr20 = abs(corr_spearman.Ret_PlusTwo).sort_values(ascending=False)[0:20].index\n",
    "corr30 = abs(corr_spearman.Ret_PlusTwo).sort_values(ascending=False)[0:30].index\n",
    "#corrPear = abs(corr_pearson.Ret_PlusTwo).sort_values(ascending=False)[0:20].index\n",
    "core=core_features.drop('Feature_7',axis='columns').columns.values\n",
    "poly15_1 = ['x1 x8','x3 x16', 'x5 x10', 'x5 x16', 'x5', 'x5 x6', 'x3 x6', 'x3 x5', 'x5 x11', 'x3 x10', 'x3^2', 'x2^2', 'x3', 'x3 x12']\n",
    "poly15_2 = abs(corr_poly.Ret_PlusTwo).sort_values(ascending=False)[0:15].index\n",
    "micpoly15 = MIC_poly.MIC_PlusOne.sort_values(ascending=False)[0:15].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 221.884 s\n",
      "training time: 236.291 s\n",
      "training time: 249.294 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'rfe10', 'rfe20', 'rfe30', 'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RFE Params\n",
    "rfe_learner = Ridge()\n",
    "rfe_params ={'alpha':100,'normalize':True,'max_iter':700,'random_state':[0]}\n",
    "rfe_learner = rfe_learner.set_params(**rfe_params)\n",
    "rfe_target = 'Ret_PlusTwo'\n",
    "\n",
    "#RFE Fitting\n",
    "rfe = RFE(rfe_learner,n_features_to_select=10, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe10 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=20, step=1, verbose=0)\n",
    "rfe.fit(all_features, y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe20 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=30, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe30 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = Ridge()\n",
    "target= 'Ret_PlusTwo'\n",
    "param_grid= {'alpha': [20,19,18,17,16,15,12,11,10,8,6,4,2,1,0.5],'normalize':[True],'max_iter':[700],'random_state':[0]}\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,rfe10,rfe20,rfe30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','rfe10','rfe20','rfe30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "         ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RFE Params\n",
    "rfe_learner = HuberRegressor()\n",
    "rfe_params ={'alpha':100,'max_iter':700}\n",
    "rfe_learner = rfe_learner.set_params(**rfe_params)\n",
    "rfe_target = 'Ret_PlusTwo'\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = HuberRegressor()\n",
    "target= 'Ret_PlusTwo'\n",
    "param_grid= {'alpha': [100,20,19,18,17,16,15,12,11],'epsilon':[1.35],'max_iter':[700]}\n",
    "\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "         ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = ExtraTreesRegressor()\n",
    "target= 'Ret_PlusTwo'\n",
    "param_grid= {'max_depth': [3],#tiefer\n",
    "             \n",
    "             'max_features': 'auto',#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [5000], #höher\n",
    "             #'min_samples_split': [],\n",
    "             'n_estimators': [100,150],#mehr bedeuten dauert länger\n",
    "             'n_jobs':[-1],\n",
    "            'random_state':[0],\n",
    "            'max_features':['sqrt']}\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "     ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "341.8873131275177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "169.02080082893372"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "221.5049660205841"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "274.0946235656738"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "176.69458651542664"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "245.8819441795349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "311.5452342033386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "199.2218315601349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "184.8338713645935"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "192.49289560317993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = GradientBoostingRegressor()\n",
    "target= 'Ret_PlusTwo'\n",
    "param_grid= {'loss':['lad'],\n",
    "             'learning_rate':[0.001],\n",
    "            'max_depth': [3],\n",
    "             'n_estimators': [300,400],\n",
    "            'random_state':[0],\n",
    "            'subsample':[0.5],\n",
    "             'verbose':[0],\n",
    "            'max_features':['auto','sqrt']}\n",
    "             \n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "    display(fitting_time)\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "    ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel((\"BA_Submissions/results_\"+target+\".xls\"),header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ret_Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Ret_MinutesFut'] = df_train.loc[:, 'Ret_121':'Ret_180'].sum(axis=1)\n",
    "y['Ret_MinutesFut_20'] = df_train.loc[:, 'Ret_121':'Ret_130'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic10 = MIC.MIC_Minute.sort_values(ascending=False)[0:10].index\n",
    "mic20 = MIC.MIC_Minute.sort_values(ascending=False)[0:20].index\n",
    "mic30 = MIC.MIC_Minute.sort_values(ascending=False)[0:30].index\n",
    "corr10 = abs(corr_spearman.Ret_MinutesFut).sort_values(ascending=False)[0:10].index\n",
    "corr20 = abs(corr_spearman.Ret_MinutesFut).sort_values(ascending=False)[0:20].index\n",
    "corr30 = abs(corr_spearman.Ret_MinutesFut).sort_values(ascending=False)[0:30].index\n",
    "#corrPear = abs(corr_pearson.Ret_PlusTwo).sort_values(ascending=False)[0:20].index\n",
    "core=core_features.drop('Feature_7',axis='columns').columns.values\n",
    "poly15_1 = ['x1 x8','x3 x16', 'x5 x10', 'x5 x16', 'x5', 'x5 x6', 'x3 x6', 'x3 x5', 'x5 x11', 'x3 x10', 'x3^2', 'x2^2', 'x3', 'x3 x12']\n",
    "poly15_2 = poly15_2 = abs(corr_poly.Ret_MinutesFut).sort_values(ascending=False)[0:15].index\n",
    "micpoly15 = MIC_poly.MIC_Minute.sort_values(ascending=False)[0:15].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 231.161 s\n",
      "training time: 247.077 s\n",
      "training time: 260.637 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'rfe10', 'rfe20', 'rfe30', 'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rfe30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#RFE Params\n",
    "rfe_learner = Ridge()\n",
    "rfe_params ={'alpha':100,'normalize':True,'max_iter':700,'random_state':0}\n",
    "rfe_learner = rfe_learner.set_params(**rfe_params)\n",
    "rfe_target = 'Ret_MinutesFut'\n",
    "\n",
    "#RFE Fitting\n",
    "rfe = RFE(rfe_learner,n_features_to_select=10, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe10 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=20, step=1, verbose=0)\n",
    "rfe.fit(all_features, y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe20 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=30, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe30 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = Ridge()\n",
    "target= 'Ret_MinutesFut'\n",
    "param_grid= {'alpha': [100,50,35,20,10],'normalize':[True],'max_iter':[700]}\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,rfe10,rfe20,rfe30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','rfe10','rfe20','rfe30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    \n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        \n",
    "        grid[cols] = ((gs.predict(train[cols_to_use]))/60)\n",
    "    \n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        grid[cols] = ((gs.predict(test[cols_to_use]))/60)\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "     ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30', 'polycorr15_1',\n",
       "       'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = HuberRegressor()\n",
    "target= 'Ret_MinutesFut'\n",
    "param_grid= {'alpha': [20,5],'max_iter':[700]}\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,31))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    \n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        \n",
    "        grid[cols] = ((gs.predict(train[cols_to_use]))/60)\n",
    "    \n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        grid[cols] = ((gs.predict(test[cols_to_use]))/60)\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "     ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xtra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = ExtraTreesRegressor()\n",
    "target= 'Ret_MinutesFut'\n",
    "param_grid= {'max_depth': [3],#tiefer\n",
    "             \n",
    "             'max_features': 'auto',#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [5000], #höher\n",
    "             #'min_samples_split': [],\n",
    "             'n_estimators': [100,150],#mehr bedeuten dauert länger\n",
    "             'n_jobs':[-1],\n",
    "            'random_state':[0],\n",
    "            'max_features':['sqrt']}\n",
    "\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    \n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        \n",
    "        grid[cols] = ((gs.predict(train[cols_to_use]))/60)\n",
    "    \n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        grid[cols] = ((gs.predict(test[cols_to_use]))/60)\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "     ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mic30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'corr30'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = GradientBoostingRegressor()\n",
    "target= 'Ret_MinutesFut'\n",
    "param_grid= {'loss':['lad'],\n",
    "             'learning_rate':[0.001],\n",
    "            'max_depth': [3],\n",
    "             'n_estimators': [300,400],\n",
    "            'random_state':[0],\n",
    "            'subsample':[0.5],\n",
    "             'verbose':[0],\n",
    "            'max_features':['auto','sqrt']}\n",
    "             \n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets.columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    \n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        \n",
    "        grid[cols] = ((gs.predict(train[cols_to_use]))/60)\n",
    "    \n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    for cols in grid.loc[:,'Ret_121':'Ret_180'].columns:\n",
    "        grid[cols] = ((gs.predict(test[cols_to_use]))/60)\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "     ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel((\"BA_Submissions/results_\"+target+\".xls\"),header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "book = load_workbook('BA_Submissions/Results.xlsx')\n",
    "writer = pd.ExcelWriter('BA_Submissions/Results.xlsx', engine='openpyxl')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "writer.sheets['Tabelle1']\n",
    "startrow = writer.sheets['Tabelle1'].max_row\n",
    "results.to_excel(writer, index = False,header=False,startrow=startrow,sheet_name ='Tabelle1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BA_Submissions/results_Ret_MinutesFut.csv'"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"BA_Submissions/results_\"+target+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 13.916 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.338"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "\n",
    "train_grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "test_grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "#Ret_PlusOne\n",
    "rfe = RFE(rfe_learner,n_features_to_select=30, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe30 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "t0 = time.time()\n",
    "learner = Ridge()\n",
    "cols_to_use = rfe30\n",
    "target= 'Ret_PlusOne'\n",
    "param_grid= {'alpha': 20, 'copy_X': True, 'fit_intercept': True, 'max_iter': 700, 'normalize': True, 'random_state': 0, 'solver': 'auto', 'tol': 0.001}\n",
    "learner.set_params(**param_grid)\n",
    "learner.fit(train[cols_to_use],y[target])\n",
    "train_grid[target] = ((learner.predict(train[cols_to_use])))\n",
    "validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],train_grid,weights).round(5) \n",
    "test_grid[target] = ((learner.predict(test[cols_to_use])))\n",
    "\n",
    "#Ret_PlusTwo\n",
    "poly15_2 = abs(corr_poly.Ret_PlusTwo).sort_values(ascending=False)[0:15].index\n",
    "\n",
    "learner = Ridge()\n",
    "cols_to_use = poly15_2\n",
    "target= 'Ret_PlusTwo'\n",
    "param_grid= {'alpha': 15, 'copy_X': True, 'fit_intercept': True, 'max_iter': 700, 'normalize': True, 'random_state': 0, 'solver': 'auto', 'tol': 0.001}\n",
    "learner.set_params(**param_grid)\n",
    "learner.fit(train[cols_to_use],y[target])\n",
    "train_grid[target] = ((learner.predict(train[cols_to_use])))\n",
    "validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],train_grid,weights).round(5) \n",
    "test_grid[target] = ((learner.predict(test[cols_to_use])))\n",
    "\n",
    "\n",
    "\n",
    "sample['Predicted'] = test_grid.values.flatten()\n",
    "display(round(time.time()-t0, 3),s)\n",
    "sample.to_csv(\"BA_Submissions/Final.csv\", index=False)\n",
    "\n",
    "# Ret_PlusOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c997ee1c88>"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c997ee1630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(learner.coef_,index = poly15_2).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.52209953e+02, -6.29519347e+04,  9.76713542e+01,  1.34526458e+02,\n",
       "        1.18005665e+00,  4.38717642e-03,  5.00138112e-01,  1.41308528e+02,\n",
       "        2.39079513e+00,  1.23954849e+00,  2.09718871e-02,  1.61091722e+04,\n",
       "       -7.39484273e+02, -6.48670415e+00,  1.21747288e+00])"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "       'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "       'x21', 'x22'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>interaction_1</th>\n",
       "      <td>x0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_2</th>\n",
       "      <td>x1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_diff</th>\n",
       "      <td>x2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_daily_diff</th>\n",
       "      <td>x3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_sum</th>\n",
       "      <td>x4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_minute_diff</th>\n",
       "      <td>x5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_last_minute_diff</th>\n",
       "      <td>x6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_minute_sum</th>\n",
       "      <td>x7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_mean_fet_7</th>\n",
       "      <td>x8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_mean_fet_5</th>\n",
       "      <td>x9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_mad_fet_7</th>\n",
       "      <td>x10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_mad_fet_5</th>\n",
       "      <td>x11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_rank_daily_1</th>\n",
       "      <td>x12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_rank_daily_2</th>\n",
       "      <td>x13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta_120</th>\n",
       "      <td>x14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed_minute_mean</th>\n",
       "      <td>x15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute_mad</th>\n",
       "      <td>x16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR_120</th>\n",
       "      <td>x17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_Minute_Mean</th>\n",
       "      <td>x18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_Minute_MAD</th>\n",
       "      <td>x19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_Minute_Sum</th>\n",
       "      <td>x20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_Minute_Sum_MAD</th>\n",
       "      <td>x21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "interaction_1          x0\n",
       "interaction_2          x1\n",
       "daily_diff             x2\n",
       "abs_daily_diff         x3\n",
       "daily_sum              x4\n",
       "last_minute_diff       x5\n",
       "abs_last_minute_diff   x6\n",
       "last_minute_sum        x7\n",
       "grouped_mean_fet_7     x8\n",
       "grouped_mean_fet_5     x9\n",
       "grouped_mad_fet_7     x10\n",
       "grouped_mad_fet_5     x11\n",
       "grouped_rank_daily_1  x12\n",
       "grouped_rank_daily_2  x13\n",
       "Delta_120             x14\n",
       "smoothed_minute_mean  x15\n",
       "minute_mad            x16\n",
       "PR_120                x17\n",
       "fet_7_Minute_Mean     x18\n",
       "fet_7_Minute_MAD      x19\n",
       "fet_7_Minute_Sum      x20\n",
       "fet_7_Minute_Sum_MAD  x21\n",
       "0                     x22"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(X_poly.columns[0:23])\n",
    "X_coef = pd.read_csv('X_features_2.csv', index_col=0)\n",
    "X_coef.columns\n",
    "pd.DataFrame(X_poly.columns[0:23],index=X_coef.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
