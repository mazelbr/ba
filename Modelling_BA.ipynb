{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matze\\Documents\\Winton\\CRISPDM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "print(os.getcwd()) \n",
    "\n",
    "X = pd.read_csv('X_features.csv', index_col=0)\n",
    "y = pd.read_csv('y_features.csv', index_col=0)\n",
    "groups = X.pop('Feature_7')\n",
    "\n",
    "test = pd.read_csv('test_features.csv', index_col=0).drop(columns = 'Feature_7')\n",
    "sample = pd.read_csv('sample_submission_2.csv')\n",
    "df_train = pd.read_csv('train.csv').set_index('Id')\n",
    "df_test = pd.read_csv('test_2.csv').set_index('Id')\n",
    "weights = df_train.loc[:,'Weight_Intraday':'Weight_Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper\n",
    "def typecasting(df):\n",
    "    categorial_cols = ['Feature_20','Feature_5']\n",
    "    binary_cols = ['Feature_16']\n",
    "\n",
    "    for col in categorial_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    for col in binary_cols:\n",
    "        df[col] = (df[col]-1).astype('category')\n",
    "\n",
    "def trainscore(y_true,y_pred,weights):\n",
    "    weights = weights.loc[y_true.index,:]\n",
    "    daily = pd.concat([weights.Weight_Daily]*2,axis=1)\n",
    "    minute = pd.concat([weights.Weight_Intraday]*60,axis=1)\n",
    "    weights = pd.concat([minute,daily],axis=1)\n",
    "    weights.columns = df_train.loc[:,'Ret_121':'Ret_PlusTwo'].columns\n",
    "    \n",
    "    \n",
    "    wmea = (((abs(y_true-y_pred))*weights).values.flatten().sum()/y_true.size)\n",
    "    \n",
    "    \n",
    "    #minute_ret = abs(y_true.loc[:,'Ret_121':'180']-y_pred.loc[:,'Ret_121':'Ret_180'])*weights.Weight_Intraday\n",
    "    return wmea\n",
    "\n",
    "\n",
    "def create_core_features(train,test):\n",
    "    X_train=train.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    X_val=test.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    from sklearn.preprocessing import Imputer\n",
    "\n",
    "    typecasting(X_train)\n",
    "    X_train = pd.get_dummies(X_train,drop_first=True)\n",
    "\n",
    "    typecasting(X_val)\n",
    "    X_val = pd.get_dummies(X_val,drop_first=True)\n",
    "\n",
    "    imputer = Imputer(strategy='mean', axis=0)\n",
    "    X_train = pd.DataFrame(imputer.fit_transform(X_train), index= X_train.index,columns=X_train.columns)\n",
    "    X_val = pd.DataFrame(imputer.fit_transform(X_val), index= X_val.index,columns=X_val.columns)\n",
    "    X_train['Ret_MinutePast'] = train.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    X_val['Ret_MinutePast'] = test.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_features, core_features_test = create_core_features(df_train,df_test)\n",
    "# generated features is X\n",
    "#Adding the interactions to Featureset\n",
    "crafted_features = pd.read_csv('BA_Features/X_features_BA.csv', index_col=0)\n",
    "crafted_features_test = pd.read_csv('BA_Features/test_features_BA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 102) (120000, 102)\n"
     ]
    }
   ],
   "source": [
    "crafted_features['interaction_3']= crafted_features.PR_120 * crafted_features.grouped_mad_fet_7\n",
    "crafted_features_test['interaction_3']= crafted_features_test.PR_120 * test.grouped_mad_fet_7\n",
    "\n",
    "#X['interaction_4']= X.smoothed_minute_mean * X.minute_mad\n",
    "#test['interaction_4']= test.smoothed_minute_mean * test.minute_mad\n",
    "\n",
    "crafted_features['interaction_5']= crafted_features.minute_mad * crafted_features.PR_120\n",
    "crafted_features_test['interaction_5']= crafted_features_test.minute_mad * crafted_features_test.PR_120\n",
    "\n",
    "crafted_features['interaction_6']= crafted_features.smoothed_minute_mean * crafted_features.grouped_mad_fet_5\n",
    "crafted_features_test['interaction_6']= crafted_features_test.smoothed_minute_mean * crafted_features_test.grouped_mad_fet_5\n",
    "\n",
    "crafted_features['interaction_7']= crafted_features.PR_120 * crafted_features.fet_7_Minute_MAD\n",
    "crafted_features_test['interaction_7']= crafted_features_test.PR_120 * crafted_features_test.fet_7_Minute_MAD\n",
    "\n",
    "crafted_features['interaction_8']= crafted_features.fet_7_Minute_MAD * crafted_features.fet_7_Minute_Mean\n",
    "crafted_features_test['interaction_8']= crafted_features_test.fet_7_Minute_MAD * crafted_features_test.fet_7_Minute_Mean\n",
    "\n",
    "print(crafted_features.shape,crafted_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([core_features,crafted_features],axis=1).drop('Feature_7',axis='columns')\n",
    "all_features_test = pd.concat([core_features_test,crafted_features_test],axis=1).drop('Feature_7',axis='columns')\n",
    "\n",
    "features_and_target = all_features.copy()\n",
    "features_and_target['Ret_PlusOne'] = y.Ret_PlusOne\n",
    "features_and_target['Ret_PlusTwo'] = y.Ret_PlusTwo\n",
    "features_and_target['Ret_MinutesFut'] = df_train.loc[:,'Ret_121':'Ret_180'].sum(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 111.148 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "corr_spearman = features_and_target.corr(method='spearman').to_csv('BA_Features/spearman_cor.csv')\n",
    "print(\"time:\", round(time.time()-t0, 3), \"s\")\n",
    "#corr_pearson = features_and_target.corr(method='pearson').to_csv('BA_Features/pearson_cor.csv')\n",
    "#print(\"time:\", round(time.time()-t0, 3), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "n=20000\n",
    "\n",
    "t0 = time.time()\n",
    "mic_Ret_PlusOne = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0), random_state=0)\n",
    "print('Time: ',time.time()-t0)\n",
    "t0 = time.time()\n",
    "#select10 = SelectKBest(score_func=mutual_info_regression, k=20).fit(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0))\n",
    "print('Time: ',time.time()-t0)\n",
    "mic_Ret_PlusTwo = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusTwo.sample(n,random_state=0), random_state=0)\n",
    "print('Time: ',time.time()-t0)\n",
    "t0 = time.time()\n",
    "mic_Ret_Minute = mutual_info_regression(all_features.sample(n,random_state=0), df_train.loc[:,'Ret_121':'Ret_180'].sum(axis=1).sample(n,random_state=0), random_state=0)\n",
    "\n",
    "print('Time: ',time.time()-t0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([mic_Ret_PlusOne,mic_Ret_PlusTwo,mic_Ret_Minute], index = ['MIC_PlusOne','MIC_PlusTwo','MIC_Minute'],columns=all_features.columns.values).T.to_csv('BA_Features/MIC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import PolynomialFeatures\n",
    "poly=PolynomialFeatures()\n",
    "X_poly = pd.read_csv('X_features_2.csv', index_col=0)\n",
    "X_poly_test = pd.read_csv('test_features_2.csv', index_col=0)\n",
    "X_poly = pd.DataFrame(poly.fit_transform(X_poly), columns= poly.get_feature_names(),index=X_poly.index).drop(['1'],axis='columns')\n",
    "X_poly_test=pd.DataFrame(poly.fit_transform(X_poly_test), columns= poly.get_feature_names(),index=X_poly_test.index).drop(['1'],axis='columns')\n",
    "display(X_poly.head())\n",
    "display(X_poly_test.head())\n",
    "\n",
    "X_poly_and_target = X_poly.copy()\n",
    "X_poly_and_target['Ret_PlusOne'] = y.Ret_PlusOne\n",
    "X_poly_and_target['Ret_PlusTwo'] = y.Ret_PlusTwo\n",
    "X_poly_and_target['Ret_MinutesFut'] = df_train.loc[:,'Ret_121':'Ret_180'].sum(axis=1)\n",
    "\n",
    "X_poly_and_target.corr(method='spearman').to_csv('BA_Features/poly_cor.csv')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIC = pd.read_csv('BA_Features/MIC.csv', index_col=0)\n",
    "corr_spearman = pd.read_csv('BA_Features/spearman_cor.csv',index_col=0).drop(['Ret_MinutesFut','Ret_PlusOne','Ret_PlusTwo'])\n",
    "corr_poly = pd.read_csv('BA_Features/poly_cor.csv',index_col=0).drop(['Ret_MinutesFut','Ret_PlusOne','Ret_PlusTwo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIC_poly = pd.read_csv('BA_Features/MIC_Poly.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Ret_PlusOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featuresets (Needed once for each Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic10 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:10].index\n",
    "mic20 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:20].index\n",
    "mic30 = MIC.MIC_PlusOne.sort_values(ascending=False)[0:30].index\n",
    "corr10 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[0:10].index\n",
    "corr20 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[0:20].index\n",
    "corr30 = abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[0:30].index\n",
    "corrPear = abs(corr_pearson.Ret_PlusOne).sort_values(ascending=False)[0:20].index\n",
    "core=core_features.drop('Feature_7',axis='columns').columns.values\n",
    "poly15_1 = ['x1 x8','x3 x16', 'x5 x10', 'x5 x16', 'x5', 'x5 x6', 'x3 x6', 'x3 x5', 'x5 x11', 'x3 x10', 'x3^2', 'x2^2', 'x3', 'x3 x12']\n",
    "poly15_2 = abs(corr_poly.Ret_PlusOne).sort_values(ascending=False)[0:15].index\n",
    "micpoly15 = MIC_poly.MIC_PlusOne.sort_values(ascending=False)[0:15].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 3308.568 s\n",
      "training time: 3321.999 s\n",
      "training time: 3335.429 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'rfe10', 'rfe20', 'rfe30', 'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'core'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RFE Params\n",
    "rfe_learner = Ridge()\n",
    "rfe_params ={'alpha':100,'normalize':True,'max_iter':700}\n",
    "rfe_learner = rfe_learner.set_params(**rfe_params)\n",
    "rfe_target = 'Ret_PlusOne'\n",
    "\n",
    "#RFE Fitting\n",
    "rfe = RFE(rfe_learner,n_features_to_select=10, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe10 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=20, step=1, verbose=0)\n",
    "rfe.fit(all_features, y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe20 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=30, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe30 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = Ridge()\n",
    "target= 'Ret_PlusOne'\n",
    "param_grid= {'alpha': [20,19,18,17,16,15,12,11,10,8,6,4,2,1,0.5],'normalize':[True],'max_iter':[700]}\n",
    "\n",
    "results = pd.DataFrame(columns=['algo','featureset','target','fitting_time','zerobenchmark','validationmark','mae','params'])\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,rfe10,rfe20,rfe30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','rfe10','rfe20','rfe30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets[['micpoly15','core']].columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "    ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "book = load_workbook('BA_Submissions/Results.xlsx')\n",
    "writer = pd.ExcelWriter('BA_Submissions/Results.xlsx', engine='openpyxl')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "writer.sheets['Tabelle1']\n",
    "startrow = writer.sheets['Tabelle1'].max_row\n",
    "results.to_excel(writer, index = False,header=False,startrow=startrow,sheet_name ='Tabelle1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-485-e9fd15b6b52e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#RFE Fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe_learner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrfe_target\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training time:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#rfe10 = all_features.columns[rfe.get_support(indices=True)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    171\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_generate_sample_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;34m\"\"\"Private function used to _parallel_build_trees function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mrandom_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0msample_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#rfe\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfe_learner = RandomForestRegressor()\n",
    "rfe_params= {'max_depth': 3,#tiefer\n",
    "             'max_features': 'sqrt',#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': 1000, #höher\n",
    "             'n_estimators': 200}#mehr bedeuten dauert länger\n",
    "rfe_learner = rfe_learner.set_params(**rfe_params)\n",
    "rfe_target = 'Ret_PlusOne'\n",
    "\n",
    "#RFE Fitting\n",
    "rfe = RFE(rfe_learner,n_features_to_select=10, step=1, verbose=1)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "#rfe10 = all_features.columns[rfe.get_support(indices=True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "#(estimator, n_features_to_select=None, step=1, verbose=0)\n",
    "\n",
    "for name in featuresets.columns:\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "\n",
    "    train = all_features\n",
    "    test = all_features_test\n",
    "    #cols_to_use = ['Ret_MinusOne']\n",
    "    learner = HuberRegressor()\n",
    "    param_grid= {'alpha':[100,50,30,1,0.1],'epsilon':[1.35,1.8]}\n",
    "\n",
    "\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y.Ret_PlusOne, groups)\n",
    "    gs.cv_results_ \n",
    "    display(gs.best_estimator_)\n",
    "    display(gs.best_score_ )\n",
    "\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "    grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "    print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    #sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.ensemble import GradientBoostRegressor\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = GradientBoostRegressor()\n",
    "param_grid= {'bootstrap': [True, False],#kein plan also auch weg\n",
    "             'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],#tiefer\n",
    "             'max_features': ['auto', 'sqrt'],#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [1, 2, 4], #höher\n",
    "             'min_samples_split': [2, 5, 10],#kann wahrscheinlich weg\n",
    "             'n_estimators': [200, 400, 600]}#mehr bedeuten dauert länger\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ret_PlusTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic10 = MIC.MIC_PlusTwo.sort_values(ascending=False)[0:10].index\n",
    "mic20 = MIC.MIC_PlusTwo.sort_values(ascending=False)[0:20].index\n",
    "mic30 = MIC.MIC_PlusTwo.sort_values(ascending=False)[0:30].index\n",
    "corr10 = abs(corr_spearman.Ret_PlusTwo).sort_values(ascending=False)[0:10].index\n",
    "corr20 = abs(corr_spearman.Ret_PlusTwo).sort_values(ascending=False)[0:20].index\n",
    "corr30 = abs(corr_spearman.Ret_PlusTwo).sort_values(ascending=False)[0:30].index\n",
    "#corrPear = abs(corr_pearson.Ret_PlusTwo).sort_values(ascending=False)[0:20].index\n",
    "core=core_features.drop('Feature_7',axis='columns').columns.values\n",
    "poly15_1 = ['x1 x8','x3 x16', 'x5 x10', 'x5 x16', 'x5', 'x5 x6', 'x3 x6', 'x3 x5', 'x5 x11', 'x3 x10', 'x3^2', 'x2^2', 'x3', 'x3 x12']\n",
    "poly15_2 = poly15_2 = abs(corr_poly.Ret_PlusTwo).sort_values(ascending=False)[0:15].index\n",
    "micpoly15 = MIC_poly.MIC_PlusOne.sort_values(ascending=False)[0:15].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core', 'mic10', 'mic20', 'mic30', 'corr10', 'corr20', 'corr30',\n",
       "       'rfe10', 'rfe20', 'rfe30', 'polycorr15_1', 'polycorr15_2', 'micpoly15'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'micpoly15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'polycorr15_2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RFE Params\n",
    "rfe_learner = HuberRegressor()\n",
    "rfe_params ={'alpha':100,'max_iter':700}\n",
    "rfe_learner = rfe_learner.set_params(**rfe_params)\n",
    "rfe_target = 'Ret_PlusTwo'\n",
    "\n",
    "#RFE Fitting\n",
    "'''\n",
    "rfe = RFE(rfe_learner,n_features_to_select=10, step=1, verbose=1)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe10 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=20, step=1, verbose=0)\n",
    "rfe.fit(all_features, y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe20 = all_features.columns[rfe.get_support(indices=True)]\n",
    "\n",
    "rfe = RFE(rfe_learner,n_features_to_select=30, step=1, verbose=0)\n",
    "rfe.fit(all_features,y[rfe_target])\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "rfe30 = all_features.columns[rfe.get_support(indices=True)]\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model_Params\n",
    "train = pd.concat([all_features,X_poly],axis=1)\n",
    "test = pd.concat([all_features_test,X_poly_test],axis=1)\n",
    "learner = HuberRegressor()\n",
    "target= 'Ret_PlusTwo'\n",
    "param_grid= {'alpha': [100,20,19,18,17,16,15,12,11],'epsilon':[1.35],'max_iter':[700]}\n",
    "\n",
    "results = pd.DataFrame(columns=['algo','featureset','target','fitting_time','zerobenchmark','validationmark','mae','params'])\n",
    "\n",
    "\n",
    "#Choose Featuresets\n",
    "featuresets = pd.DataFrame([core,mic10,mic20,mic30,corr10,corr20,corr30,rfe10,rfe20,rfe30,poly15_1,poly15_2,micpoly15],index=['core','mic10','mic20','mic30','corr10','corr20','corr30','rfe10','rfe20','rfe30','polycorr15_1','polycorr15_2','micpoly15'],columns=list(range(1,43))).T\n",
    "display(featuresets.columns)\n",
    "#Fitting\n",
    "\n",
    "for name in featuresets[['micpoly15','polycorr15_2']].columns:\n",
    "\n",
    "\n",
    "    cols_to_use = featuresets[name].dropna()\n",
    "    \n",
    "    t0=time.time()\n",
    "    gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "    gs.fit(train[cols_to_use], y[target], groups)\n",
    "    gs.cv_results_ \n",
    "    #display(gs.best_estimator_)\n",
    "    #display(gs.best_score_ )\n",
    "    display(name)\n",
    "    fitting_time = time.time()-t0\n",
    "    #Trainscore\n",
    "    grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "    grid.shape\n",
    "    zerobenchmark= trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5)\n",
    "    grid[target] = ((gs.predict(train[cols_to_use])))\n",
    "    validationbenchmark = trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) \n",
    "\n",
    "\n",
    "    ###Submission\n",
    "    grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "    grid.shape\n",
    "\n",
    "    grid[target] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "    sample['Predicted'] = grid.values.flatten()\n",
    "    sample.to_csv(('BA_Submissions/'+str(learner).split('(',1)[0]+'_'+name+target+\".csv\"), index=False)\n",
    "\n",
    "    ###Output\n",
    "    algo = str(learner).split('(',1)[0]\n",
    "    params= gs.best_estimator_.get_params()\n",
    "    mae = abs(gs.best_score_)\n",
    "    results = results.append(pd.DataFrame([algo,name,target,fitting_time,zerobenchmark,validationbenchmark,mae,params],index=results.columns).T, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>featureset</th>\n",
       "      <th>target</th>\n",
       "      <th>fitting_time</th>\n",
       "      <th>zerobenchmark</th>\n",
       "      <th>validationmark</th>\n",
       "      <th>mae</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>poly15_1</td>\n",
       "      <td>Ret_PlusTwo</td>\n",
       "      <td>31.4027</td>\n",
       "      <td>1773.92</td>\n",
       "      <td>1773.75</td>\n",
       "      <td>0.0151833</td>\n",
       "      <td>{'alpha': 100, 'epsilon': 1.35, 'fit_intercept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>poly15_2</td>\n",
       "      <td>Ret_PlusTwo</td>\n",
       "      <td>19.3254</td>\n",
       "      <td>1773.92</td>\n",
       "      <td>1773.26</td>\n",
       "      <td>0.0151685</td>\n",
       "      <td>{'alpha': 11, 'epsilon': 1.35, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algo featureset       target fitting_time zerobenchmark  \\\n",
       "0  HuberRegressor   poly15_1  Ret_PlusTwo      31.4027       1773.92   \n",
       "1  HuberRegressor   poly15_2  Ret_PlusTwo      19.3254       1773.92   \n",
       "\n",
       "  validationmark        mae                                             params  \n",
       "0        1773.75  0.0151833  {'alpha': 100, 'epsilon': 1.35, 'fit_intercept...  \n",
       "1        1773.26  0.0151685  {'alpha': 11, 'epsilon': 1.35, 'fit_intercept'...  "
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
