{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matze\\Documents\\Winton\\CRISPDM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "print(os.getcwd()) \n",
    "\n",
    "X = pd.read_csv('X_features.csv', index_col=0)\n",
    "y = pd.read_csv('y_features.csv', index_col=0)\n",
    "groups = X.pop('Feature_7')\n",
    "\n",
    "test = pd.read_csv('test_features.csv', index_col=0).drop(columns = 'Feature_7')\n",
    "sample = pd.read_csv('sample_submission_2.csv')\n",
    "df_train = pd.read_csv('train.csv').set_index('Id')\n",
    "df_test = pd.read_csv('test_2.csv').set_index('Id')\n",
    "weights = df_train.loc[:,'Weight_Intraday':'Weight_Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper\n",
    "def typecasting(df):\n",
    "    categorial_cols = ['Feature_20','Feature_5']\n",
    "    binary_cols = ['Feature_16']\n",
    "\n",
    "    for col in categorial_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    for col in binary_cols:\n",
    "        df[col] = (df[col]-1).astype('category')\n",
    "\n",
    "def trainscore(y_true,y_pred,weights):\n",
    "    weights = weights.loc[y_true.index,:]\n",
    "    daily = pd.concat([weights.Weight_Daily]*2,axis=1)\n",
    "    minute = pd.concat([weights.Weight_Intraday]*60,axis=1)\n",
    "    weights = pd.concat([minute,daily],axis=1)\n",
    "    weights.columns = df_train.loc[:,'Ret_121':'Ret_PlusTwo'].columns\n",
    "    \n",
    "    \n",
    "    wmea = (((abs(y_true-y_pred))*weights).values.flatten().sum()/y_true.size)\n",
    "    \n",
    "    \n",
    "    #minute_ret = abs(y_true.loc[:,'Ret_121':'180']-y_pred.loc[:,'Ret_121':'Ret_180'])*weights.Weight_Intraday\n",
    "    return wmea\n",
    "\n",
    "\n",
    "def create_core_features(train,test):\n",
    "    X_train=train.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    X_val=test.loc[:,'Feature_1':'Ret_MinusOne']\n",
    "    from sklearn.preprocessing import Imputer\n",
    "\n",
    "    typecasting(X_train)\n",
    "    X_train = pd.get_dummies(X_train,drop_first=True)\n",
    "\n",
    "    typecasting(X_val)\n",
    "    X_val = pd.get_dummies(X_val,drop_first=True)\n",
    "\n",
    "    imputer = Imputer(strategy='mean', axis=0)\n",
    "    X_train = pd.DataFrame(imputer.fit_transform(X_train), index= X_train.index,columns=X_train.columns)\n",
    "    X_val = pd.DataFrame(imputer.fit_transform(X_val), index= X_val.index,columns=X_val.columns)\n",
    "    X_train['Ret_MinutePast'] = train.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    X_val['Ret_MinutePast'] = test.loc[:,'Ret_2':'Ret_120'].sum(axis=1)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_features, core_features_test = create_core_features(df_train,df_test)\n",
    "# generated features is X\n",
    "#Adding the interactions to Featureset\n",
    "crafted_features = pd.read_csv('BA_Features/X_features_BA.csv', index_col=0)\n",
    "crafted_features_test = pd.read_csv('BA_Features/test_features_BA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 102) (120000, 102)\n"
     ]
    }
   ],
   "source": [
    "crafted_features['interaction_3']= crafted_features.PR_120 * crafted_features.grouped_mad_fet_7\n",
    "crafted_features_test['interaction_3']= crafted_features_test.PR_120 * test.grouped_mad_fet_7\n",
    "\n",
    "#X['interaction_4']= X.smoothed_minute_mean * X.minute_mad\n",
    "#test['interaction_4']= test.smoothed_minute_mean * test.minute_mad\n",
    "\n",
    "crafted_features['interaction_5']= crafted_features.minute_mad * crafted_features.PR_120\n",
    "crafted_features_test['interaction_5']= crafted_features_test.minute_mad * crafted_features_test.PR_120\n",
    "\n",
    "crafted_features['interaction_6']= crafted_features.smoothed_minute_mean * crafted_features.grouped_mad_fet_5\n",
    "crafted_features_test['interaction_6']= crafted_features_test.smoothed_minute_mean * crafted_features_test.grouped_mad_fet_5\n",
    "\n",
    "crafted_features['interaction_7']= crafted_features.PR_120 * crafted_features.fet_7_Minute_MAD\n",
    "crafted_features_test['interaction_7']= crafted_features_test.PR_120 * crafted_features_test.fet_7_Minute_MAD\n",
    "\n",
    "crafted_features['interaction_8']= crafted_features.fet_7_Minute_MAD * crafted_features.fet_7_Minute_Mean\n",
    "crafted_features_test['interaction_8']= crafted_features_test.fet_7_Minute_MAD * crafted_features_test.fet_7_Minute_Mean\n",
    "\n",
    "print(crafted_features.shape,crafted_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([core_features,crafted_features],axis=1).drop('Feature_7',axis='columns')\n",
    "all_features_test = pd.concat([core_features_test,crafted_features_test],axis=1).drop('Feature_7',axis='columns')\n",
    "\n",
    "features_and_target = all_features.copy()\n",
    "features_and_target['Ret_PlusOne'] = y.Ret_PlusOne\n",
    "features_and_target['Ret_PlusTwo'] = y.Ret_PlusTwo\n",
    "features_and_target = features_and_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "corr_spearman = features_and_target.corr(method='spearman').to_csv('BA_Features/spearman_cor.csv')\n",
    "print(\"time:\", round(time.time()-t0, 3), \"s\")\n",
    "corr_pearson = features_and_target.corr(method='pearson').to_csv('BA_Features/pearson_cor.csv')\n",
    "print(\"time:\", round(time.time()-t0, 3), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interaction_8                 0.065062\n",
       "fet_7_Minute_Mean             0.060549\n",
       "interaction_5                 0.038164\n",
       "interaction_3                 0.037041\n",
       "interaction_7                 0.036667\n",
       "Delta_last_5                  0.036181\n",
       "interaction_6                 0.036009\n",
       "smoothed_minute_sum           0.035779\n",
       "smoothed_minute_mean          0.035779\n",
       "interaction_1                 0.035623\n",
       "PR_Last_10                    0.035519\n",
       "Delta_119                     0.035339\n",
       "PR_120                        0.035120\n",
       "Ret_MinutePast                0.033987\n",
       "Delta_120                     0.033637\n",
       "minute_sum                    0.033637\n",
       "minute_mean                   0.033637\n",
       "Delta_last_60                 0.032584\n",
       "fet_7_absdiff_RetDaily_Mad    0.032109\n",
       "Name: Ret_PlusOne, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(corr_spearman.Ret_PlusOne).sort_values(ascending=False)[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interaction_2           0.133803\n",
       "interaction_3           0.111315\n",
       "PR_Last_30              0.108404\n",
       "interaction_8           0.102100\n",
       "PR_Last_60              0.098852\n",
       "interaction_7           0.098168\n",
       "last_minute_diff        0.098035\n",
       "Delta_last_60           0.096432\n",
       "fet_7_Minute_Mean       0.095669\n",
       "PR_Last_10              0.092923\n",
       "interaction_5           0.091822\n",
       "Delta_119               0.091589\n",
       "abs_last_minute_diff    0.088304\n",
       "Delta_last_10           0.088294\n",
       "interaction_6           0.084366\n",
       "smoothed_minute_mean    0.084310\n",
       "smoothed_minute_sum     0.084310\n",
       "Ret_MinutePast          0.084249\n",
       "minute_mean             0.083243\n",
       "Name: Ret_PlusOne, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(corr_pearson.Ret_PlusOne).sort_values(ascending=False)[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  3044.978446006775\n",
      "Time:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "n=40000\n",
    "\n",
    "t0 = time.time()\n",
    "mic_Ret_PlusOne = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0), random_state=0)\n",
    "print('Time: ',time.time()-t0)\n",
    "t0 = time.time()\n",
    "#select10 = SelectKBest(score_func=mutual_info_regression, k=20).fit(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0))\n",
    "print('Time: ',time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mic_Ret_PlusTwo = mutual_info_regression(all_features.sample(n,random_state=0), y.Ret_PlusOne.sample(n,random_state=0), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mic_Ret_PlusOne, index = all_features.columns.values,columns=['MIC_PlusOne']).sort_values('MIC_PlusOne',ascending=False).to_csv('BA_Features/MIC_PlusOne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIC_PlusOne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>minute_std</th>\n",
       "      <td>0.134975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute_sem</th>\n",
       "      <td>0.134975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed_minute_std</th>\n",
       "      <td>0.134404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed_minute_sem</th>\n",
       "      <td>0.134404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute_var</th>\n",
       "      <td>0.131280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed_minute_var</th>\n",
       "      <td>0.129490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute_median</th>\n",
       "      <td>0.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute_mad</th>\n",
       "      <td>0.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAD_120</th>\n",
       "      <td>0.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed_minute_mad</th>\n",
       "      <td>0.125025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed_minute_median</th>\n",
       "      <td>0.125025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAD_last_60</th>\n",
       "      <td>0.121356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAD_last_30</th>\n",
       "      <td>0.118102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAD_first_60</th>\n",
       "      <td>0.117168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_Minute_MAD</th>\n",
       "      <td>0.113217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_RetMinOne_Mad</th>\n",
       "      <td>0.106232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_mad_fet_7</th>\n",
       "      <td>0.105986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAD_last_15</th>\n",
       "      <td>0.098697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute_25_quantile</th>\n",
       "      <td>0.096351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_RetMinTwo_Mad</th>\n",
       "      <td>0.096194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_Minute_Mean</th>\n",
       "      <td>0.095683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute_75_quantile</th>\n",
       "      <td>0.095680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_diff_RetDaily_Mean</th>\n",
       "      <td>0.095341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_RetMinOne_Mean</th>\n",
       "      <td>0.092896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_RetMinTwo_Median</th>\n",
       "      <td>0.092650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_mean_fet_7</th>\n",
       "      <td>0.092543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_8</th>\n",
       "      <td>0.091936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_RetMinTwo_Mean</th>\n",
       "      <td>0.091548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fet_7_RetMinOne_Median</th>\n",
       "      <td>0.089448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.086971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_MinusTwo</th>\n",
       "      <td>0.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_rank_daily_2</th>\n",
       "      <td>0.002996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothed_minute_kurt</th>\n",
       "      <td>0.002880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbsDiff_Ranked</th>\n",
       "      <td>0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_18</th>\n",
       "      <td>0.002790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_1</th>\n",
       "      <td>0.002458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_5_9.0</th>\n",
       "      <td>0.002416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_10</th>\n",
       "      <td>0.002342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAD_div_15_120</th>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_5_8.0</th>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_20_9.0</th>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_20_8.0</th>\n",
       "      <td>0.001508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_20_4.0</th>\n",
       "      <td>0.001171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_20_7.0</th>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_5_2.0</th>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum_Ranked</th>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_5_10.0</th>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_16_1.0</th>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_20_5.0</th>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grouped_rank_daily_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_5_4.0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_5_5.0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_5_7.0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_20_3.0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta_div_60_60</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_MinusOne</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff_Ranked</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MIC_PlusOne\n",
       "minute_std                   0.134975\n",
       "minute_sem                   0.134975\n",
       "smoothed_minute_std          0.134404\n",
       "smoothed_minute_sem          0.134404\n",
       "minute_var                   0.131280\n",
       "smoothed_minute_var          0.129490\n",
       "minute_median                0.127389\n",
       "minute_mad                   0.127389\n",
       "MAD_120                      0.127389\n",
       "smoothed_minute_mad          0.125025\n",
       "smoothed_minute_median       0.125025\n",
       "MAD_last_60                  0.121356\n",
       "MAD_last_30                  0.118102\n",
       "MAD_first_60                 0.117168\n",
       "fet_7_Minute_MAD             0.113217\n",
       "fet_7_RetMinOne_Mad          0.106232\n",
       "grouped_mad_fet_7            0.105986\n",
       "MAD_last_15                  0.098697\n",
       "minute_25_quantile           0.096351\n",
       "fet_7_RetMinTwo_Mad          0.096194\n",
       "fet_7_Minute_Mean            0.095683\n",
       "minute_75_quantile           0.095680\n",
       "fet_7_diff_RetDaily_Mean     0.095341\n",
       "fet_7_RetMinOne_Mean         0.092896\n",
       "fet_7_RetMinTwo_Median       0.092650\n",
       "grouped_mean_fet_7           0.092543\n",
       "interaction_8                0.091936\n",
       "fet_7_RetMinTwo_Mean         0.091548\n",
       "fet_7_RetMinOne_Median       0.089448\n",
       "0                            0.086971\n",
       "...                               ...\n",
       "Rank_MinusTwo                0.003052\n",
       "grouped_rank_daily_2         0.002996\n",
       "smoothed_minute_kurt         0.002880\n",
       "AbsDiff_Ranked               0.002802\n",
       "Feature_18                   0.002790\n",
       "Feature_1                    0.002458\n",
       "Feature_5_9.0                0.002416\n",
       "Feature_10                   0.002342\n",
       "MAD_div_15_120               0.002314\n",
       "Feature_5_8.0                0.002011\n",
       "Feature_20_9.0               0.001608\n",
       "Feature_20_8.0               0.001508\n",
       "Feature_20_4.0               0.001171\n",
       "Feature_20_7.0               0.001076\n",
       "Feature_5_2.0                0.000918\n",
       "Sum_Ranked                   0.000863\n",
       "Feature_5_10.0               0.000640\n",
       "Feature_16_1.0               0.000381\n",
       "Feature_20_5.0               0.000182\n",
       "Feature_12                   0.000000\n",
       "Feature_15                   0.000000\n",
       "grouped_rank_daily_1         0.000000\n",
       "Feature_5_4.0                0.000000\n",
       "Feature_5_5.0                0.000000\n",
       "Feature_5_7.0                0.000000\n",
       "Feature_20_3.0               0.000000\n",
       "Delta_div_60_60              0.000000\n",
       "Rank_MinusOne                0.000000\n",
       "Diff_Ranked                  0.000000\n",
       "Feature_24                   0.000000\n",
       "\n",
       "[144 rows x 1 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mic_Ret_PlusOne, index = all_features.columns.values,columns=['MIC_PlusOne']).sort_values('MIC_PlusOne',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAD_120',\n",
       " 'MAD_last_60',\n",
       " 'MAD_first_60',\n",
       " 'MAD_last_30',\n",
       " 'MAD_last_15',\n",
       " 'fet_7_RetMinTwo_Mad',\n",
       " 'smoothed_minute_mad',\n",
       " 'smoothed_minute_median',\n",
       " 'smoothed_minute_std',\n",
       " 'smoothed_minute_var',\n",
       " 'smoothed_minute_sem',\n",
       " 'minute_mad',\n",
       " 'minute_median',\n",
       " 'minute_std',\n",
       " 'minute_var',\n",
       " 'minute_sem',\n",
       " 'minute_25_quantile',\n",
       " 'minute_75_quantile',\n",
       " 'fet_7_Minute_MAD',\n",
       " '0']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.columns[select10.get_support(indices=True)].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Ret_PlusOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=12, copy_X=True, fit_intercept=True, max_iter=700, normalize=True,\n",
       "   random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.015770296333707377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Benchmark:  1773.9244\n",
      "Validation Benchmark:  1773.83633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = Ridge()\n",
    "param_grid= {'alpha': [20,19,18,17,16,15,12,11],'normalize':[False, True],'max_iter':[700]}\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfe\n",
    "n = 20\n",
    "\n",
    "t0=time.time()\n",
    "rfe = RFE(gs.best_estimator_,n_features_to_select=n, step=1, verbose=1)\n",
    "rfe.fit(train, y.Ret_PlusOne)\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "\n",
    "cols_to_use = train.columns[rfe.get_support(indices=True)]\n",
    "gs= GridSearchCV(gbm, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "\n",
    "\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "sample.to_csv('submissions/GBM_featureset_RFE_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.linear_model import Huber\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "#(estimator, n_features_to_select=None, step=1, verbose=0)\n",
    "\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = Huber()\n",
    "param_grid= {'alpha': [100,20,19,18,17,16,15,12,11,1,0.1],'epsilon':[1,1.35,1.8],'max_iter':[700]}\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = RandomForestRegressor()\n",
    "param_grid= {'bootstrap': [True, False],#kein plan also auch weg\n",
    "             'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],#tiefer\n",
    "             'max_features': ['auto', 'sqrt'],#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [1, 2, 4], #höher\n",
    "             'min_samples_split': [2, 5, 10],#kann wahrscheinlich weg\n",
    "             'n_estimators': [200, 400, 600]}#mehr bedeuten dauert länger\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "group_shuffle = GroupShuffleSplit(n_splits=10, test_size=0.60, train_size=0.4, random_state=0)\n",
    "from sklearn.ensemble import GradientBoostRegressor\n",
    "\n",
    "train = all_features\n",
    "test = all_features_test\n",
    "cols_to_use = ['Ret_MinusOne']\n",
    "learner = GradientBoostRegressor()\n",
    "param_grid= {'bootstrap': [True, False],#kein plan also auch weg\n",
    "             'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],#tiefer\n",
    "             'max_features': ['auto', 'sqrt'],#wahrscheinlich weniger glaub kürzere fitting time\n",
    "             'min_samples_leaf': [1, 2, 4], #höher\n",
    "             'min_samples_split': [2, 5, 10],#kann wahrscheinlich weg\n",
    "             'n_estimators': [200, 400, 600]}#mehr bedeuten dauert länger\n",
    "\n",
    "\n",
    "gs= GridSearchCV(learner, param_grid, iid=False, refit=True, cv=group_shuffle, return_train_score =True, scoring='neg_mean_absolute_error')\n",
    "gs.fit(X[cols_to_use], y.Ret_PlusOne, groups)\n",
    "gs.cv_results_ \n",
    "display(gs.best_estimator_)\n",
    "display(gs.best_score_ )\n",
    "\n",
    "#Trainscore\n",
    "grid = pd.DataFrame(np.zeros([40000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns,index=df_train.index)\n",
    "grid.shape\n",
    "print(\"Zero Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "grid['Ret_PlusOne'] = ((gs.predict(train[cols_to_use])))\n",
    "print(\"Validation Benchmark: \",trainscore(df_train.loc[:,'Ret_121':'Ret_PlusTwo'],grid,weights).round(5) )\n",
    "\n",
    "\n",
    "###Submission\n",
    "grid = pd.DataFrame(np.zeros([120000, 62]), columns = df_train.loc[:, 'Ret_121':'Ret_PlusTwo'].columns)\n",
    "grid.shape\n",
    "\n",
    "grid['Ret_PlusOne'] = ((gs.predict(test[cols_to_use])))\n",
    "\n",
    "sample['Predicted'] = grid.values.flatten()\n",
    "#sample.to_csv('submissions/featureset_RFE_20_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
