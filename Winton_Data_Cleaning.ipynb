{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matze\\Documents\\Winton\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "print(os.getcwd()) \n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test_2.csv')\n",
    "sample = pd.read_csv('sample_submission_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing Values:: ['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_6', 'Feature_8', 'Feature_9', 'Feature_10', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17', 'Feature_18', 'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24', 'Feature_25', 'Ret_2', 'Ret_3', 'Ret_4', 'Ret_5', 'Ret_6', 'Ret_7', 'Ret_8', 'Ret_9', 'Ret_10', 'Ret_11', 'Ret_12', 'Ret_13', 'Ret_14', 'Ret_15', 'Ret_16', 'Ret_17', 'Ret_18', 'Ret_19', 'Ret_20', 'Ret_21', 'Ret_22', 'Ret_23', 'Ret_24', 'Ret_25', 'Ret_26', 'Ret_27', 'Ret_28', 'Ret_29', 'Ret_30', 'Ret_31', 'Ret_32', 'Ret_33', 'Ret_34', 'Ret_35', 'Ret_36', 'Ret_37', 'Ret_38', 'Ret_39', 'Ret_40', 'Ret_41', 'Ret_42', 'Ret_43', 'Ret_44', 'Ret_45', 'Ret_46', 'Ret_47', 'Ret_48', 'Ret_49', 'Ret_50', 'Ret_51', 'Ret_52', 'Ret_53', 'Ret_54', 'Ret_55', 'Ret_56', 'Ret_57', 'Ret_58', 'Ret_59', 'Ret_60', 'Ret_61', 'Ret_62', 'Ret_63', 'Ret_64', 'Ret_65', 'Ret_66', 'Ret_67', 'Ret_68', 'Ret_69', 'Ret_70', 'Ret_71', 'Ret_72', 'Ret_73', 'Ret_74', 'Ret_75', 'Ret_76', 'Ret_77', 'Ret_78', 'Ret_79', 'Ret_80', 'Ret_81', 'Ret_82', 'Ret_83', 'Ret_84', 'Ret_85', 'Ret_86', 'Ret_87', 'Ret_88', 'Ret_89', 'Ret_90', 'Ret_91', 'Ret_92', 'Ret_93', 'Ret_94', 'Ret_95', 'Ret_96', 'Ret_97', 'Ret_98', 'Ret_99', 'Ret_100', 'Ret_101', 'Ret_102', 'Ret_103', 'Ret_104', 'Ret_105', 'Ret_106', 'Ret_107', 'Ret_108', 'Ret_109', 'Ret_110', 'Ret_111', 'Ret_112', 'Ret_113', 'Ret_114', 'Ret_115', 'Ret_116', 'Ret_117', 'Ret_118', 'Ret_119']\n",
      "Short:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Columns: 211 entries, Id to Weight_Daily\n",
      "dtypes: float64(209), int64(2)\n",
      "memory usage: 64.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#print(\"Column Names:::\", df_train.columns.values.tolist())\n",
    "print(\"Columns with missing Values::\", df_train.columns[df_train.isnull().any()].tolist())\n",
    "### columns without missing values\n",
    "print(\"Short:\")\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got an overall Trainning DataSet with 40,000 entries and 25 static features, 2 daily and 119 minute returnrates from the past and 2 Daily return rates and 60 minute rates from the future\n",
    "\n",
    "In the dataset is an ID columns which is unnecessary and can be droped and two Features (5 and 7) with no missing values on which we'll have a special focus\n",
    "Feature 5 might be categorial so we want to hotencode it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop('Id', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Feature_5 = df_train.Feature_5.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Feature_5_dummies = pd.get_dummies(df_train.Feature_5, prefix  = \"Feature_5\")\n",
    "df_train = pd.concat([df_train, Feature_5_dummies], axis = 1, verify_integrity = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5',\n",
       "       'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10',\n",
       "       ...\n",
       "       'Feature_5_1', 'Feature_5_2', 'Feature_5_3', 'Feature_5_4',\n",
       "       'Feature_5_5', 'Feature_5_6', 'Feature_5_7', 'Feature_5_8',\n",
       "       'Feature_5_9', 'Feature_5_10'],\n",
       "      dtype='object', length=156)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:, 'Feature_1':'Ret_120'].columns.append(Feature_5_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.loc[:, (df_train.loc[:, 'Feature_1':'Ret_120'].columns.append(Feature_5_dummies.columns))]\n",
    "y = df_train.loc[:, 'Ret_121':'Ret_PlusTwo']\n",
    "weight_daily = df_train.Weight_Daily\n",
    "weight_intraday = df_train.Weight_Intraday\n",
    "featureset = df_train.loc[:, 'Feature_1':'Feature_25']\n",
    "featureset_encoded  = df_train.loc[:, (featureset.columns.append(Feature_5_dummies.columns))]\n",
    "daily_ret_past = df_train.loc[:, 'Ret_MinusTwo':'Ret_MinusOne']\n",
    "daily_ret_fut = df_train.loc[:, 'Ret_PlusOne':'Ret_PlusOne']\n",
    "minute_ret_past = df_train.loc[:, 'Ret_2':'Ret_120']\n",
    "minute_ret_fut = df_train.loc[:, 'Ret_121':'Ret_180']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_daily.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle = False, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_pipeline = Pipeline([\n",
    " ('imputer', Imputer(axis=1))\n",
    "])\n",
    "feature_pipeline = Pipeline([\n",
    " ('imputer', Imputer())\n",
    " ])\n",
    "daily_pipeline = Pipeline([\n",
    " ('imputer', Imputer())\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit and transform on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_minute_prep = pd.DataFrame(minute_pipeline.fit_transform(X_train.loc[:, minute_ret_past.columns]), columns= minute_ret_past.columns, index = X_train.index)\n",
    "X_train_daily_prep = pd.DataFrame(daily_pipeline.fit_transform(X_train.loc[:, daily_ret_past.columns]), columns= daily_ret_past.columns, index = X_train.index)\n",
    "X_train_feature_prep = pd.DataFrame(feature_pipeline.fit_transform(X_train.loc[:, featureset_encoded.columns]), columns= featureset_encoded.columns, index = X_train.index)\n",
    "\n",
    "X_train_prep = pd.concat([X_train_feature_prep, X_train_daily_prep, X_train_minute_prep] ,axis='columns', verify_integrity = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_minute_prep =  pd.DataFrame(minute_pipeline.transform(X_test.loc[:, minute_ret_past.columns]), columns= minute_ret_past.columns, index = X_test.index)\n",
    "X_test_daily_prep =  pd.DataFrame(daily_pipeline.transform(X_test.loc[:, daily_ret_past.columns]), columns= daily_ret_past.columns, index = X_test.index)\n",
    "X_test_feature_prep =  pd.DataFrame(feature_pipeline.transform(X_test.loc[:, featureset_encoded.columns]), columns= featureset_encoded.columns, index = X_test.index)\n",
    "\n",
    "\n",
    "X_test_prep = pd.concat([X_test_feature_prep, X_test_daily_prep, X_test_minute_prep] ,axis='columns', verify_integrity = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export cleaned Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame.to_csvÂ¶(\"Clean Data/\")\n",
    "X_train_prep.to_csv(\"Clean Data/X_train_prep.csv\")\n",
    "X_test_prep.to_csv(\"Clean Data/X_test_prep.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(\"Clean Data/y_train_prep.csv\")\n",
    "y_test.to_csv(\"Clean Data/y_test_prep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_daily.to_csv(\"Clean Data/weight_daily.csv\")\n",
    "weight_intraday.to_csv(\"Clean Data/weight_intraday.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_daily.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
